# Домашнее задание к занятию «Репликация и масштабирование. Часть 2» - Наталья Мартынова (Пономарева)

### Задание 1

1. активный master-сервер и пассивный репликационный slave-сервер; 

Намного чаще репликацию Master-Slave используют не для масштабирования, а для резервирования. 
В этом случае, Мастер сервер обрабатывает все запросы от приложения. 
Слейв сервер работает в пассивном режиме. Но в случае выхода из строя Мастера, все операции переключаются на Слейв.  
 
Преимущества:

- При сбоях можно выполнить средствами репликации слияние изменений, а также просмотреть двоичные журналы, чтобы увидеть, какие обновления были применены к разным узлам.
- Чтение можно выполнять с любой ноды кластера, slave или master. Но выгоднее со Slave для распределения нагрузки.
- Резервное копирование БД не влияет на master, т.к. можно делать со slave
- slave-сервер может падать и лежать в downtime для проведения плановых работ без простоя сервиса в целом.
  
Недостатки:

- Запись и изменение данных только через master-ноду, т.е. нагрузку нельзя распределить балансировщиком
- Асинхронность репликации означает, что данные на Слейве могут появиться с небольшой задержкой. Поэтому, в последовательных операциях необходимо использовать чтение с Мастера, чтобы получить актуальные данные
- В случае сбоя master необходимо вручную переводить slave-ноду в роль мастера, нет автоматического восстановления
- Если мастер лежит, то это downtime сервиса и вероятная потеря данных
- Каждая дополнительная slave-нода увеличивает нагрузку на master, т.к. часто происходит чтение журнала и копирование данных

2. master-сервер и несколько slave-серверов;  
По сравнению с "master и один slave" - преимущество в масштабировании на чтение данных, а также в количестве "запасных вариантов" восстановления из реплики при сбое.
И чем больше slave-серверов, тем больше нагрузка на CPU master-сервера для поддержания актуальности серверов slave (даже с полусинхронной репликацией).  
А также следует учитывать, что на slave-серверах данные появляются с задержкой. Поэтому такая репликация полезна лишь для специфичных сервисов БД, с малым потоком на запись и большим потоком на чтение данных без требований актуальности.

3. активный сервер со специальным механизмом репликации — distributed replicated block device (DRBD);

Это только про репликацию. DRBD создает копии данных на двух устройствах хранения для того, чтобы в случае сбоя одного из них можно было использовать данные на втором.

Преимущества:
- Синхронное реплицирование данных, в то время как master-slave - асинхронное
- DRBD предполагает обеспечение отказоустойчивости. Если база данных потеряна, то можно перезапустить её с использованием зеркального тома. Обеспечивает автоматическое переключение на другой ресурс, защищает от потери данных и автоматически синхронизирует отказавший мастер MySQL после переключения
- DRBD реплицирует все блочное устройство, основная информация, такая как двоичные журналы, также реплицируется. Поэтому в случае сбоя можно восстановить БД
- DRBD предлагает большую независимость по сравнению с SAN и лучше с точки зрения высокой доступности
- С DRBD вероятность потери синхронизации минимальна и может быть вызвана программными и аппаратными ошибками, а не проблемами репликации MySQL, например.    
 
Недостатки:
- Нет масштабирования и распределения нагрузки - нельзя работать с зеркальным томом, поскольку его операционная система не может управлять записью на него; с точки зрения наблюдателя данные на зеркальном томе появляются сами собой. В случае аварии (отказ основного сервера или всего ЦОДа, где находится основной сервер) следует остановить репликацию, размонтировать основной том и смонтировать зеркальный том. Как только появится возможность, следует перезапустить репликацию в обратном направлении.
- Сама СУБД на резервном сервере может быть запущена только после монтирования диска. В некоторых операционных системах, например, в Solaris, память под кеш при выделении размечается, и время разметки пропорционально объёму выделяемой памяти, т.е. старт будет долгим. Плюс ко всему кеш после рестарта будет пуст.
- После запуска на резервном сервере СУБД обнаружит, что данные на диске неконсистентны, и нужно потратить значительное время на восстановление с применением журналов повторного выполнения: сначала повторить те транзакции, результаты которых сохранились в журнале, но не успели сохраниться в файлы данных. А потом откатить транзакции, которые к моменту сбоя не успели завершиться. Чем больше база, тем дольше будет восстановление.

4. SAN-кластер.
 
Предшественник DRBD, внешнее устройство хранения, что позволяет монтировать его на нескольких серверах единовременно
 
Преимущества:
- В случае репликации средствами дискового массива трафик идёт не по сети передачи данных (LAN), а по сети хранения данных (Storage Area Network).  
- Зачастую в инфраструктурах, построенных давно, SAN гораздо надёжнее и производительнее, чем сеть передачи данных.  
- На реплике можно выполнять запросы, сняв тем самым часть нагрузки с основной базы. В частности, реплику можно использовать для создания резервных копий.
- Физическая репликация может быть как синхронной, так и асинхронной. 

Недостатки:
- Более затратно
- Решение было актуально, когда средства репликации БД были не настолько надежны

---

### Задание 2

Для начала, нужно представить, что это за магазины и сколько данных в таблицах. Раз нам понадобилось шардирование, скорее всего бизнес крупный:
- пользователи - с учетом истории (неактивных пользователей, логинов) строк в таблице от 500 тыс. до 1 млн  
- книги - сотни миллионов позиций  
- магазины - небольшая таблица, вряд ли больше от 100 до 1000 строк  

Стратегия: книги и пользователей выносим в отдельные БД (вертикальное шардирование) и горизонтально шардируем таблицу с книгами (по четности book_id, чтобы соблюсти баланс шардов).  
Магазины можно было бы оставить с одной из других БД, но книги и так переполнены, а users, вероятнее всего, содержит персональные данные, и требования к этой БД выше.
Для обеспечения отказоустойчивости необходимо резервировать сервера баз данных с помощью репликации master-slave. 
В таком случае, каждый шард будет иметь резервный сервер с копией данных.

Блок-схемы:
![Снимок1](https://github.com/NatoshFehn/hw-rbd-07/blob/main/Снимок1.png)  
![Снимок2](https://github.com/NatoshFehn/hw-rbd-07/blob/main/Снимок2.png)  
